# 完全分布式环境搭建

### 1.克隆模板机

以hadoop101为模板克隆出102

修改ip配置文件 hostname文件重启

```
vim /etc/sysconfig/network-scripts/ifcfg-ens33
将IPADDR进行更改,保存并退出
vim /etc/hostname
改为当前主机名
reboot重启
```

将本地的java和hadoop的tar包上传到software目录下 

解压到moudle目录下

```
tar -zxvf /opt/software/jdk-8u212-linux-x64.tar.gz -C /opt/module/
tar -zxvf /opt/software/hadoop-3.1.3.tar.gz -C /opt/module/
```

配置环境变量

新建/etc/profile.d/my_env.sh文件

```
sudo vim /etc/profile.d/my_env.sh
```

添加如下内容

```
#JAVA_HOME
export JAVA_HOME=/opt/module/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin

#HADOOP_HOME
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin:$PATH:$HADOOP_HOME/sbin
```

保存并退出

source一下/etc/profile文件，让新的环境变量PATH生效

测试是否安装成功

```
java -version
hadoop version
```



### 2.群发文件脚本

在atguigu用户下新建bin目录 创建myrsync.sh

mkdir bin

vim /bin/myrsync.sh

#!/bin/bash

```
#!/bin/bash
#参数判空
if [ $# -lt 1 ]
then
echo "参数不能为空"
exit
fi


for host in hadoop102 hadoop103 hadoop104
do
echo ===========$host=============
        for file in $@
        do
        #判断文件是否存在
        if [ -e $file ]
        then
        #存在
        #1.获取分发文件的父级路径
        pdir=$(cd -P $(dirname $file); pwd)
        #2.获取分发内容名称
        filename=$(basename $file);
        #3.远程登录到目标服务器创建目标路径
        ssh $host "mkdir -p $pdir"
        #4.拷贝内容
        rsync -av $pdir/$filename $host:$pdir
        else
        #不存在
        echo "$file 不存在"
        exit
        fi
        done
done
```

修改脚本权限

```
chmod 777 myrsync.sh
```

配置到环境变量

```
source /etc/profile
```

### 3.克隆102虚拟机

以hadoop102为模板克隆出hadoop103,hadoop104

修改ip配置文件以及hostname

source 环境变量

### 3.SSH无密配置登录

生成公钥私钥

```
ssh-keygen -t rsa
```

将公钥拷贝到要免密登录的机器上

```
ssh-copy-id hadoop102
ssh-copy-id hadoop103
ssh-copy-id hadoop104
```

### 4.集群配置

修改配置文件

```
配置core-site.xml
[atguigu@hadoop102 ~]$ cd $HADOOP_HOME/etc/hadoop
[atguigu@hadoop102 hadoop]$ vim core-site.xml
文件内容如下：
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
    <!-- 指定NameNode的地址 -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop102:9820</value>
    </property>

    <!-- 指定hadoop数据的存储目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-3.1.3/data</value>
    </property>

    <!-- 配置HDFS网页登录使用的静态用户为atguigu -->
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>atguigu</value>
    </property>
</configuration>
```

```
配置hdfs-site.xml
[atguigu@hadoop102 hadoop]$ vim hdfs-site.xml
文件内容如下：
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	<!-- nn web端访问地址-->
	<property>
        <name>dfs.namenode.http-address</name>
        <value>hadoop102:9870</value>
    </property>
	<!-- 2nn web端访问地址-->
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop104:9868</value>
    </property>
</configuration>
```

```
配置yarn-site.xml
[atguigu@hadoop102 hadoop]$ vim yarn-site.xml
文件内容如下：
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
    <!-- 指定MR走shuffle -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>

    <!-- 指定ResourceManager的地址-->
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop103</value>
    </property>

    <!-- 环境变量的继承 -->
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
    
<!-- 开启日志聚集功能 -->

<property>

  <name>yarn.log-aggregation-enable</name>

  <value>true</value>

</property>

<!-- 设置日志聚集服务器地址 -->

<property>  

  <name>yarn.log.server.url</name>  

  <value>http://hadoop102:19888/jobhistory/logs</value>

</property>

<!-- 设置日志保留时间为7天 -->

<property>

  <name>yarn.log-aggregation.retain-seconds</name>

  <value>604800</value>

</property>
</configuration>
```

```
配置mapred-site.xml
[atguigu@hadoop102 hadoop]$ vim mapred-site.xml
文件内容如下：
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	<!-- 指定MapReduce程序运行在Yarn上 -->
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
<!-- 历史服务器端地址 -->
<property>

  <name>mapreduce.jobhistory.address</name>

  <value>hadoop102:10020</value>

</property>

<!-- 历史服务器web端地址 -->

<property>

  <name>mapreduce.jobhistory.webapp.address</name>

  <value>hadoop102:19888</value>

</property>
</configuration>
```

分发配置文件

```
myrsync.sh /opt/module/hadoop-3.1.3/etc/hadoop
```

查看文件分发情况

```
[atguigu@hadoop103 ~]$ cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml
[atguigu@hadoop104 ~]$ cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml
```

### 5.群起集群

配置workers

```
vim /opt/module/hadoop-3.1.3/etc/hadoop/workers
```

添加如下

```
hadoop102
hadoop103
hadoop104
```

同步所有节点配置文件

```
myrsync.sh /opt/module/hadoop-3.1.3/etc
```

封装群起群停脚本myhadoop.sh在/bin目录下

```
#!/bin/bash

#参数判空
if [ $# -lt 1 ]
then 
echo "参数不能为空"
exit
fi

case $1 in
"start")
echo "===========启动HDFS============="
ssh hadoop102 /opt/module/hadoop-3.1.3/sbin/start-dfs.sh
echo "===========启动YARN============="
ssh hadoop103 /opt/module/hadoop-3.1.3/sbin/start-yarn.sh
;;
"stop")
echo "===========停止HDFS============="
ssh hadoop102 /opt/module/hadoop-3.1.3/sbin/stop-dfs.sh
echo "===========停止YARN============="
ssh hadoop103 /opt/module/hadoop-3.1.3/sbin/stop-yarn.sh
;;
*)
echo "参数有误"
esac
```

封装jpsall.sh脚本在/bin目录下

```
#!/bin/bash
for host in hadoop102 hadoop103 hadoop104
do
echo ==============$host==================
ssh $host jps
done

```

将自定义脚本分发给其他服务器

myrsync.sh /home/atguigu/bin

所有服务器重新加载环境变量

source /etc/profile

第一次启动hdfs要进行初始化

```
[atguigu@hadoop102 hadoop-3.1.3]$ hdfs namenode -format
```

群起集群

```
myhadoop.sh start
```

查看服务启动情况

```
jpsall.shjp
```

### 6.配置历史服务器

配置mapred-site.xml

```
[atguigu@hadoop102 hadoop]$ vim mapred-site.xml
```

在该文件里面增加如下配置。

```
<!-- 历史服务器端地址 -->
<property>

  <name>mapreduce.jobhistory.address</name>

  <value>hadoop102:10020</value>

</property>

 

<!-- 历史服务器web端地址 -->

<property>

  <name>mapreduce.jobhistory.webapp.address</name>

  <value>hadoop102:19888</value>

</property>
```

分发给其他节点服务器

```
myrsync.sh $HADOOP_HOME/etc/hadoop/mapred-site.xml
```

hadoop102启动历史服务器

```
[atguigu@hadoop102 hadoop]$ mapred --daemon start historyserver
```

### 7.配置日志聚集

配置yarn-site.xml

```
[atguigu@hadoop102 hadoop]$ vim yarn-site.xml
```

在该文件里面增加如下配置。

```
<!-- 开启日志聚集功能 -->

<property>

  <name>yarn.log-aggregation-enable</name>

  <value>true</value>

</property>

<!-- 设置日志聚集服务器地址 -->

<property>  

  <name>yarn.log.server.url</name>  

  <value>http://hadoop102:19888/jobhistory/logs</value>

</property>

<!-- 设置日志保留时间为7天 -->

<property>

  <name>yarn.log-aggregation.retain-seconds</name>

  <value>604800</value>

</property>
```

2)配置

```
[atguigu@hadoop102 hadoop]$ myrsync.sh $HADOOP_HOME/etc/hadoop/yarn-site.xml
```

3)关闭NodeManager 、ResourceManager和HistoryServer

```
[atguigu@hadoop103 hadoop-3.1.3]$ sbin/stop-yarn.sh
[atguigu@hadoop102 hadoop-3.1.3]$ mapred --daemon stop historyserver
```

4）启动NodeManager 、ResourceManage和HistoryServer

```
[atguigu@hadoop103 ~]$ start-yarn.sh
[atguigu@hadoop102 ~]$ mapred --daemon start historyserver
```



5）删除HDFS上已经存在的输出文件

```
[atguigu@hadoop102 ~]$ hadoop fs -rm -r /output
```

6）执行WordCount程序

```
[atguigu@hadoop102 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output
```

